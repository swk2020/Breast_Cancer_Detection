{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier,  plot_tree\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# This code will use decsion tree classification for a binary label classification task.\n",
    "\n",
    "# The classification model used is arbitrary the main focus is on the error metrics.\n",
    "\n",
    "# Including:\n",
    "# Confusions Matrix (2x2) inc true positives, true negatives, false positives, false negatives.\n",
    "# Overall accuracy aka classification accuracy\n",
    "# Misclassification Rate\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "# Specificity or true negative rate\n",
    "# Precision or positive predictive value\n",
    "# F1 Score\n",
    "# Negative predictive value\n",
    "# Fall out or false positive rate\n",
    "# False negative rate\n",
    "# False discovery rate\n",
    "# F1 Score\n",
    "# ROC curves\n",
    "# AUC\n",
    "# Mean Absolute Error\n",
    "# Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the sk learn breast cancer data set\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = pd.Series(cancer.target)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features are all the columns except the target (has breast cancer)\n",
    "X = df[df.columns[:-1]]\n",
    "\n",
    "# Target is the has breast cancer target column\n",
    "y = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "# Instatiate a decision tree classifier object\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model with the training X and y\n",
    "clf_dt = clf_dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was actually 89 +ve cases of breast cancer\n",
      "There was actually 54 -ve cases of breast cancer\n",
      "\n",
      " The accuracy score when predicting the test data 0.9440559440559441\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict the test data y_test\n",
    "y_test_pred = clf_dt.predict(X_test)\n",
    "\n",
    "# Then compare it to  the actual y_test data using this confusion matrix\n",
    "plot_confusion_matrix(clf_dt, X_test, y_test, display_labels=[\"No Cancer\", \"Has Cancer\"])\n",
    "\n",
    "# What is the accuracy of the model when it predicts the test Data (should be lower)  \n",
    "print('There was actually ' + str(y_test.sum()) + ' +ve cases of breast cancer')\n",
    "print('There was actually ' + str(len(y_test)-y_test.sum()) + ' -ve cases of breast cancer')\n",
    "print ('')\n",
    "print(f' The accuracy score when predicting the test data {accuracy_score(y_test_pred,y_test)}')\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Metrics and Confusion Matrix Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions can fall into one of 4 categories:\n",
    "\n",
    "TN = True Negative, correctly identifying the lack of event A\n",
    "\n",
    "FN = False Negative, incorrectly identifying the lack of event A\n",
    "\n",
    "TP = True Positive, correctly identiying event A as happening\n",
    "\n",
    "FP = False Positive, incorrectly identiying event A as happening\n",
    "\n",
    "We say that the positive case is the label/class/category that we are interested in that we are trying to predict.\n",
    "\n",
    "The negative is simply the alternative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a 2x2 stand bivariate classification task confusion matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "CM = metrics.confusion_matrix(y_true = y_test, y_pred = y_test_pred)\n",
    "\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy aka classification accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "# Misclassification Rate\n",
    "MR = 1 - ACC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438202247191011"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "\n",
    "# F1 Score\n",
    "F1 = 2 * ((PPV*TPR)/(PPV+TPR))\n",
    "\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# F1 Score\n",
    "F1 = 2 * ((PPV*TPR)/(PPV+TPR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05555555555555555"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC :\n",
    "\n",
    "ROC is a Receiver Operator Characteristic Graph.\n",
    "\n",
    "Say you have a DTC model and you want to alter a single parameter and see how a range of values of it can change the quality of the model.\n",
    "\n",
    "Instead of producing a confusion matrix for every tree:\n",
    "\n",
    "We plot a set of TPR (Sensitivity) values against FPR (1 - specificity) values, a data point for each model.\n",
    "\n",
    "\n",
    "The data points with the highest TPR and lowest FPR should be considered as the optimal value for the parameter.\n",
    "\n",
    "Usually this is the one in the nearest to the top left corner.\n",
    "\n",
    "Why? because a perfect classifier would have 1 TPR and 0 FPR.\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "![alt text](ROC.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to make a model for each of the potential decision trees.\n",
    "\n",
    "# One for every combination of variables.\n",
    "\n",
    "DTC_ParaMeters = {\"criterion\": [ \"gini\", \"entropy\"] ,\n",
    "                  \"splitter\" :[\"best\", \"random\"] , \n",
    "                  \"max_depth\" : [None,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "allNames = sorted(DTC_ParaMeters)\n",
    "combinations = it.product(*(DTC_ParaMeters[Name] for Name in allNames))\n",
    "list_of_variations = list(combinations)\n",
    "print(len(list_of_variations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gini', None, 'best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_variations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criterion', 'max_depth', 'splitter']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2, 1), indices imply (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1674\u001b[0m                 blocks = [\n\u001b[1;32m-> 1675\u001b[1;33m                     make_block(\n\u001b[0m\u001b[0;32m   1676\u001b[0m                         \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   2741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2742\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    143\u001b[0m                 \u001b[1;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-98ebf59ac873>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mROC_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mTPR\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mFPR\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mModel_Results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROC_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'TPR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FRP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1685\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"values\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1687\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2, 1), indices imply (2, 2)"
     ]
    }
   ],
   "source": [
    "# Instatiate a decision tree classifier object\n",
    "clf_dt = DecisionTreeClassifier(criterion = list_of_variations[0][0],  max_depth = list_of_variations[0][1], splitter = list_of_variations[0][2])\n",
    "\n",
    "# Train the model with the training X and y\n",
    "clf_dt = clf_dt.fit(X_train, y_train)\n",
    "\n",
    "# predict the test data y_test\n",
    "y_test_pred = clf_dt.predict(X_test)\n",
    "\n",
    "CM = metrics.confusion_matrix(y_true = y_test, y_pred = y_test_pred)\n",
    "\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0]\n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "FPR = FP/(FP+TN)\n",
    "\n",
    "ROC_iteration = np.array([ TPR , FPR ])\n",
    "\n",
    "Model_Results = pd.DataFrame(ROC_iteration, columns = ['TPR','FRP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
